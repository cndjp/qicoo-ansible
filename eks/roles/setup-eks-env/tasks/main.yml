- name: "Setup EKS Cluster & Managing Account"
  cloudformation:
     stack_name: "{{ EKS.SPINNAKER.MANAGING_ACOUNT_STACK }}"
     template: "{{ ansible_env.PWD }}/files/eks-spinnaker-managing.yaml"
     disable_rollback: true
     template_parameters:
        UseAccessKeyForAuthentication: "false"
        EksClusterName: "{{ EKS.CLUSTER.CLUSTER_NAME }}"
     region: "{{ REGION }}"


- name: "Register VPC ID"
  shell: |
     aws cloudformation describe-stacks \ 
          --stack-name {{ EKS.SPINNAKER.MANAGING_ACOUNT_STACK }} \
          --query 'Stacks[0].Outputs[?OutputKey==`VpcId`].OutputValue' \ 
          --output text
  register: E_S_VPC_ID

- name: "Register Secrity Group"
  shell: |
     aws cloudformation describe-stacks \
          --stack-name {{ EKS.SPINNAKER.MANAGING_ACOUNT_STACK }} \
          --query  'Stacks[0].Outputs[?OutputKey==`SecurityGroups`].OutputValue' \
          --output text
  register: E_S_CONTROL_PLANE_SG

- name: "Register Auth ARN"
  shell: |
     aws cloudformation describe-stacks \
          --stack-name {{ EKS.SPINNAKER.MANAGING_ACOUNT_STACK }} \
          --query  'Stacks[0].Outputs[?OutputKey==`AuthArn`].OutputValue' \
          --output text
  register: E_S_AUTH_ARN

- name: "Register Subnets"
  shell: |
     aws cloudformation describe-stacks \
          --stack-name {{ EKS.SPINNAKER.MANAGING_ACOUNT_STACK }} \
          --query  'Stacks[0].Outputs[?OutputKey==`SubnetIds`].OutputValue' \
          --output text
  register: E_S_SUBNETS

- name: "Register Managing id"
  shell: |
     aws cloudformation describe-stacks \
          --stack-name {{ EKS.SPINNAKER.MANAGING_ACOUNT_STACK }} \
          --query  'Stacks[0].Outputs[?OutputKey==`ManagingAccountId`].OutputValue' \
          --output text
  register: E_S_MANAGING_ACCOUNT_ID

- name: "Register EKS Cluster Endpoint"
  shell: |
     aws cloudformation describe-stacks \
          --stack-name {{ EKS.SPINNAKER.MANAGING_ACOUNT_STACK }} \
          --query  'Stacks[0].Outputs[?OutputKey==`EksClusterEndpoint`].OutputValue' \
          --output text
  register: E_S_EKS_CLUSTER_ENDPOINT

- name: "Register EKS Cluster Name"
  shell: |
     aws cloudformation describe-stacks \
          --stack-name {{ EKS.SPINNAKER.MANAGING_ACOUNT_STACK }} \
          --query  'Stacks[0].Outputs[?OutputKey==`EksClusterName`].OutputValue' \
          --output text
  register: E_S_EKS_CLUSTER_NAME

- name: "Register EKS CA Data"
  shell: |
     aws cloudformation describe-stacks \
          --stack-name {{ EKS.SPINNAKER.MANAGING_ACOUNT_STACK }} \
          --query  'Stacks[0].Outputs[?OutputKey==`EksClusterCA`].OutputValue' \
          --output text
  register: E_S_EKS_CA_DATA

- name: "Register Spinnaker Instance Profile ARN"
  shell: |
     aws cloudformation describe-stacks \
          --stack-name {{ EKS.SPINNAKER.MANAGING_ACOUNT_STACK }} \
          --query  'Stacks[0].Outputs[?OutputKey==`SpinnakerInstanceProfileArn`].OutputValue' \
          --output text
  register: E_S_SPINNAKER_INSTANCE_PROFILE_ARN

- name: "Setup Managed Account"
  cloudformation:
     stack_name: "{{ EKS.SPINNAKER.MANAGED_ACOUNT_STACK }}"
     state: "present"
     disable_rollback: true
     template: "{{ ansible_env.PWD }}/files/eks-spinnaker-managed.yaml"
     template_parameters:
        AuthArn: "{{ E_S_AUTH_ARN.stdout }}"
        ManagingAccountId: "{{ E_S_MANAGING_ACCOUNT_ID.stdout }}"
     region: "{{ REGION }}"

- name: "Create .kube dir"
  file:
    dest=~/.kube/
    state=directory
    owner={{ WORK_USER.NAME }}
    group={{ WORK_USER.GROUP }}

- name: "Create K8S Config"
  template:
    src={{ ansible_env.PWD }}/template/config.j2
    dest=~/.kube/config
    owner={{ WORK_USER.NAME }}
    group={{ WORK_USER.GROUP }}
  tags:
    - always

- name: "Create Namespace"
  shell: |
     kubectl apply -f {{ ansible_env.PWD }}/files/eks-spinnaker-namespace.yaml

- name: "Create Spinakker Service Account"
  shell: |
     kubectl apply -f {{ ansible_env.PWD }}/files/eks-spinnaker-serviceaccount.yaml && \
     kubectl apply -f {{ ansible_env.PWD }}/files/eks-spinnaker-clusterrolebinding.yaml

- name: "Register EKS Secret"
  shell: |
     kubectl get serviceaccount {{ EKS.SPINNAKER.SERVICE_ACOUNT }} \
        --context {{ EKS.SPINNAKER.CONTEXT }} \
        -n spinnaker \
        -o jsonpath='{.secrets[0].name}' 
  register: E_S_SECRET

- name: "Register EKS Token"
  shell: |
     kubectl get secret {{ E_S_SECRET.stdout }} \ 
        --context {{ EKS.SPINNAKER.CONTEXT }} \
        -n spinnaker \
        -o jsonpath='{.data.token}' | base64 --decode
  register: E_S_TOKEN

- name: "Setup Context User"
  shell: |
     kubectl config set-credentials {{ EKS.SPINNAKER.CONTEXT }}-token-user --token {{ E_S_TOKEN.stdout }} && \
     kubectl config set-context {{ EKS.SPINNAKER.CONTEXT }} --user {{ EKS.SPINNAKER.CONTEXT }}-token-user

- name: "Check Hal config Exists"
  stat: path=~/.hal/config
  register: checkhalconfigexists
  ignore_errors: True

- name: "Setup Halyard CloudProvider"
  shell: |
     hal config provider kubernetes enable && \
     hal config provider kubernetes account add kubernetes-master --provider-version v2 --context $(kubectl config current-context) && \
     hal config features edit --artifacts true
  when: checkhalconfigexists.stat.exists == False

- name: "Deploy EC2 NodeGroup"
  cloudformation:
     stack_name: "{{ EKS.SPINNAKER.EC2_NODEGROUP }}"
     disable_rollback: true
     template: "{{ ansible_env.PWD }}/files/eks-spinnaker-nodegroup.yaml"
     template_parameters:
        NodeInstanceProfile: "{{ E_S_SPINNAKER_INSTANCE_PROFILE_ARN.stdout }}"
        NodeInstanceType: "{{ EKS.CLUSTER.FLAVOR }}"
        ClusterName: "{{ EKS.CLUSTER.CLUSTER_NAME }}"
        NodeGroupName: "{{ EKS.SPINNAKER.EC2_NODEGROUP }}"
        ClusterControlPlaneSecurityGroup: "{{ E_S_CONTROL_PLANE_SG.stdout }}"
        Subnets: "{{ E_S_SUBNETS.stdout }}"
        VpcId: "{{ E_S_VPC_ID.stdout }}"
        NodeAutoScalingGroupMinSize: "{{ EKS.CLUSTER.MIN_NODE }}"
        NodeAutoScalingGroupMaxSize: "{{ EKS.CLUSTER.MAX_NODE }}"
     region: "{{ REGION }}"

- name: "Create AWS Auth Configmap Template"
  template:
    src={{ ansible_env.PWD }}/template/eks-awsauth-configmap.yaml.j2
    dest={{ ansible_env.PWD }}/files/eks-awsauth-configmap.yaml
    owner={{ WORK_USER.NAME }}
    group={{ WORK_USER.GROUP }}
  tags:
    - alway

- name: "Create AWS Auth Configmap"
  shell: |
     kubectl apply -f {{ ansible_env.PWD }}/files/eks-awsauth-configmap.yaml

